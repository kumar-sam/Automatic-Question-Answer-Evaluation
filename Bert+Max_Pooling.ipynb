{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert+Max_Pooling.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMthsbscgAx+iAMSrqZH0j3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumar-sam/Automatic-Question-Answer-Evaluation/blob/main/Bert%2BMax_Pooling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2S76ywmct5F5"
      },
      "source": [
        "## SBert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvJASEMYsRUj",
        "outputId": "d2ba3fa9-1591-49d5-f3ec-7af29472bb08"
      },
      "source": [
        "!pip install tensorflow\n",
        "!pip install transformers\n",
        "!pip list | grep -E 'transformers|tokenizers'"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.33.2)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.5)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.35.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow) (50.3.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.17.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.5.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: tokenizers==0.9.3 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "tokenizers                    0.9.3          \n",
            "transformers                  3.5.1          \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0kjlQ3KsWCX"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hzj4ctIIsWGI"
      },
      "source": [
        "#Max Pooling - Take the max value over time for every dimension\n",
        "def max_pooling(model_output, attention_mask):\n",
        "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    token_embeddings[input_mask_expanded == 0] = -1e9  # Set padding tokens to large negative value\n",
        "    max_over_time = torch.max(token_embeddings, 1)[0]\n",
        "    return max_over_time"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRVTX-S037MB"
      },
      "source": [
        "#Sentences we want sentence embeddings for\n",
        "\n",
        "sentences = [\n",
        " 'Machine Learning is the science of getting computers to learn and act like humans do, and improve their learning over time in autonomous fashion, by feeding them data and information in the form of observations and real-world interactions.',\n",
        " 'Machine Learning (ML) can be explained as automating and improving the learning process of computers based on their experiences without being actually programmed i.e. without any human assistance. The process starts with feeding good quality data and then training our machines(computers) by building machine learning models using the data and different algorithms. The choice of algorithms depends on what type of data do we have and what kind of task we are trying to automate.',\n",
        " 'Data science is an inter-disciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from many structural and unstructured data. Data science is related to data mining, machine learning and big data.',\n",
        " 'software engineers are really good in coding they are a good team player and good in mathematics',\n",
        " 'Joint Entrance Examination – Advanced (JEE-Advanced), formerly the Indian Institutes of Technology-Joint Entrance Examination (IIT-JEE), is an academic examination held annually in India. It is conducted by one of the seven zonal IITs (IIT Roorkee, IIT Kharagpur, IIT Delhi, IIT Kanpur, IIT Bombay, IIT Madras, and IIT Dharwad) under the guidance of the Joint Admission Board (JAB). It is the sole prerequisite for admission to the Indian Institutes of Technology. Other universities like the Rajiv Gandhi Institute of Petroleum Technology, Indian Institute of Science Education and Research and the Indian Institute of Science also use the score obtained on the JEE-Advanced exam as the basis for admission. The examination is organised each year by one of the IITs, on a round-robin rotation pattern.',\n",
        " \"The president of India, officially the President of the Republic of India (IAST: Bhārat kē Rāṣhṭrapati), is the ceremonial head of state of India and the Commander-in-chief of the Indian Armed Forces.The president is indirectly elected by an electoral college comprising the Parliament of India (both houses) and the legislative assemblies of each of India's states and territories, who themselves are all directly elected.\",\n",
        "]"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb7qCK5Zsihz"
      },
      "source": [
        "#Load AutoModel from huggingface model repository\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/bert-base-nli-max-tokens\")\n",
        "model = AutoModel.from_pretrained(\"sentence-transformers/bert-base-nli-max-tokens\")\n",
        "\n",
        "#Tokenize sentences\n",
        "encoded_input = tokenizer(sentences, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
        "\n",
        "#Compute token embeddings\n",
        "with torch.no_grad():\n",
        "    model_output = model(**encoded_input)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6eP_kEispnK",
        "outputId": "8d9a9133-e8f1-4c57-a6db-559e4037e373"
      },
      "source": [
        "model_output[1]"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.6785, -0.3811, -0.3117,  ..., -0.8613, -0.6026,  0.4337],\n",
              "        [-0.4550, -0.4918, -0.2056,  ..., -0.6448, -0.4818,  0.1482],\n",
              "        [-0.7266, -0.3246, -0.1335,  ..., -0.9099, -0.6470,  0.7198],\n",
              "        [ 0.2156,  0.0120, -0.8795,  ..., -0.8673,  0.1825, -0.6063],\n",
              "        [-0.6515, -0.4800, -0.3298,  ..., -0.6480, -0.1953,  0.0141],\n",
              "        [-0.8324, -0.5395, -0.7741,  ..., -0.9241, -0.5157,  0.1302]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbixIEbAsilr",
        "outputId": "d7b06ae0-57a7-48db-d374-7a0ba6f49714"
      },
      "source": [
        "#Perform pooling. In this case, max pooling\n",
        "sentence_embeddings_sbert = max_pooling(model_output, encoded_input['attention_mask'])\n",
        "\n",
        "print(\"Sentence embeddings:\")\n",
        "print(sentence_embeddings_sbert)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence embeddings:\n",
            "tensor([[ 5.4378e-02,  9.6291e-01,  1.9213e+00,  ...,  1.6476e-01,\n",
            "         -5.0602e-01,  5.4386e-01],\n",
            "        [ 2.4989e-01,  1.3479e+00,  1.3915e+00,  ...,  2.0159e-01,\n",
            "         -2.6415e-01,  8.0529e-01],\n",
            "        [ 3.3215e-01,  1.5401e+00,  2.8933e-01,  ..., -1.6547e-01,\n",
            "          8.3750e-03,  4.5810e-01],\n",
            "        [ 1.8371e-01,  9.1992e-01, -4.8081e-01,  ...,  4.1432e-01,\n",
            "         -9.3064e-04,  2.4924e-01],\n",
            "        [ 6.5023e-01,  1.1848e+00,  1.3291e+00,  ...,  6.5337e-01,\n",
            "          1.5838e+00,  1.3274e+00],\n",
            "        [ 7.8597e-01,  4.7389e-01,  4.5608e-01,  ..., -9.9444e-02,\n",
            "          9.9268e-01,  1.3300e+00]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeBymi0ZtKU5",
        "outputId": "45161413-9b93-42f9-cdf5-6b979751b22d"
      },
      "source": [
        "np.array(model_output[0]).shape"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 128, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wy1Ch2zLtf3H",
        "outputId": "0e234294-2935-43f9-d543-d1d658ed7383"
      },
      "source": [
        "np.array(model_output[1]).shape"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vuAPOjCsiqF",
        "outputId": "dc8e1c09-35ea-4784-f1a7-5f16c0def0bd"
      },
      "source": [
        "import numpy as np \n",
        "np.array(sentence_embeddings).shape"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wTfAzQftsYt",
        "outputId": "08fcbb7a-433d-48cf-9709-6a429a335aff"
      },
      "source": [
        "sentence_embeddings_sbert"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5.4378e-02,  9.6291e-01,  1.9213e+00,  ...,  1.6476e-01,\n",
              "         -5.0602e-01,  5.4386e-01],\n",
              "        [ 2.4989e-01,  1.3479e+00,  1.3915e+00,  ...,  2.0159e-01,\n",
              "         -2.6415e-01,  8.0529e-01],\n",
              "        [ 3.3215e-01,  1.5401e+00,  2.8933e-01,  ..., -1.6547e-01,\n",
              "          8.3750e-03,  4.5810e-01],\n",
              "        [ 1.8371e-01,  9.1992e-01, -4.8081e-01,  ...,  4.1432e-01,\n",
              "         -9.3064e-04,  2.4924e-01],\n",
              "        [ 6.5023e-01,  1.1848e+00,  1.3291e+00,  ...,  6.5337e-01,\n",
              "          1.5838e+00,  1.3274e+00],\n",
              "        [ 7.8597e-01,  4.7389e-01,  4.5608e-01,  ..., -9.9444e-02,\n",
              "          9.9268e-01,  1.3300e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5ZxgaiyyBGZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPNwJPr8ttPi"
      },
      "source": [
        "## Bert + Max Pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8f4HIWVtsc2"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import transformers as ppb # pytorch transformers\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtQZrUU-xOMq"
      },
      "source": [
        "#Max Pooling - Take the max value over time for every dimension\n",
        "def max_pooling(model_output, attention_mask):\n",
        "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    token_embeddings[input_mask_expanded == 0] = -1e9  # Set padding tokens to large negative value\n",
        "    max_over_time = torch.max(token_embeddings, 1)[0]\n",
        "    return max_over_time"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vbk5NfWx3l1d"
      },
      "source": [
        "#Sentences we want sentence embeddings for\n",
        "\n",
        "sentences = [\n",
        " 'Machine Learning is the science of getting computers to learn and act like humans do, and improve their learning over time in autonomous fashion, by feeding them data and information in the form of observations and real-world interactions.',\n",
        " 'Machine Learning (ML) can be explained as automating and improving the learning process of computers based on their experiences without being actually programmed i.e. without any human assistance. The process starts with feeding good quality data and then training our machines(computers) by building machine learning models using the data and different algorithms. The choice of algorithms depends on what type of data do we have and what kind of task we are trying to automate.',\n",
        " 'Data science is an inter-disciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from many structural and unstructured data. Data science is related to data mining, machine learning and big data.',\n",
        " 'software engineers are really good in coding they are a good team player and good in mathematics',\n",
        " 'Joint Entrance Examination – Advanced (JEE-Advanced), formerly the Indian Institutes of Technology-Joint Entrance Examination (IIT-JEE), is an academic examination held annually in India. It is conducted by one of the seven zonal IITs (IIT Roorkee, IIT Kharagpur, IIT Delhi, IIT Kanpur, IIT Bombay, IIT Madras, and IIT Dharwad) under the guidance of the Joint Admission Board (JAB). It is the sole prerequisite for admission to the Indian Institutes of Technology. Other universities like the Rajiv Gandhi Institute of Petroleum Technology, Indian Institute of Science Education and Research and the Indian Institute of Science also use the score obtained on the JEE-Advanced exam as the basis for admission. The examination is organised each year by one of the IITs, on a round-robin rotation pattern.',\n",
        " \"The president of India, officially the President of the Republic of India (IAST: Bhārat kē Rāṣhṭrapati), is the ceremonial head of state of India and the Commander-in-chief of the Indian Armed Forces.The president is indirectly elected by an electoral college comprising the Parliament of India (both houses) and the legislative assemblies of each of India's states and territories, who themselves are all directly elected.\",\n",
        "]"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZS_0q8NxTAA"
      },
      "source": [
        "#Load AutoModel from huggingface model repository\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "#Tokenize sentences\n",
        "encoded_input = tokenizer(sentences, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
        "\n",
        "#Compute token embeddings\n",
        "with torch.no_grad():\n",
        "    model_output = model(**encoded_input)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPAjEbOpxqxU",
        "outputId": "90a981ab-f294-46bc-98a2-9ec9bfad6b77"
      },
      "source": [
        "model_output"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 0.1730, -0.2285, -0.4436,  ..., -0.0600, -0.2608,  0.6115],\n",
              "          [ 0.4410,  0.4642, -0.6297,  ...,  0.3118,  0.7988,  0.6890],\n",
              "          [ 0.3267,  0.3485, -0.6775,  ..., -0.4906,  0.1210,  0.7811],\n",
              "          ...,\n",
              "          [ 0.3720,  0.1589, -0.0394,  ..., -0.5004, -0.4275,  0.0529],\n",
              "          [-0.4392, -0.2352, -0.3201,  ...,  0.1480,  0.0387, -0.2422],\n",
              "          [-0.3278, -0.3365, -0.3303,  ...,  0.0835, -0.1275, -0.0612]],\n",
              " \n",
              "         [[ 0.1139, -0.1046, -0.1401,  ..., -0.3234, -0.2775,  0.7110],\n",
              "          [ 0.1873,  0.3992, -0.1844,  ...,  0.4850,  0.8252,  0.4604],\n",
              "          [ 0.1450,  0.3667, -0.0930,  ..., -0.5656, -0.2463,  0.8268],\n",
              "          ...,\n",
              "          [-0.2153, -0.4368, -0.0599,  ...,  0.0941,  0.1570,  0.0618],\n",
              "          [-0.1771, -0.3815,  0.2083,  ..., -0.1897, -0.1277,  0.2641],\n",
              "          [-0.1634, -0.3891,  0.1858,  ..., -0.1735, -0.1737,  0.2126]],\n",
              " \n",
              "         [[ 0.1438, -0.3382, -0.4895,  ..., -0.1735, -0.2984,  0.7280],\n",
              "          [ 0.0452, -0.0023, -0.2324,  ...,  0.2091,  0.7673,  0.2560],\n",
              "          [-0.1807,  0.6633, -1.1347,  ..., -0.2864,  0.0127,  0.3594],\n",
              "          ...,\n",
              "          [ 0.1304,  0.0088,  0.1290,  ..., -0.6891, -0.5465, -0.0089],\n",
              "          [-0.3971, -0.7371, -0.4065,  ...,  0.2310,  0.3169, -0.0083],\n",
              "          [-0.0381, -0.2149,  0.1986,  ..., -0.1552, -0.1790,  0.2563]],\n",
              " \n",
              "         [[ 0.1039,  0.3671, -0.3329,  ..., -0.8287,  0.7350,  0.4272],\n",
              "          [ 0.3363,  0.2657, -0.2076,  ..., -0.6105,  0.5881,  0.2635],\n",
              "          [ 0.5736,  0.7119, -0.7245,  ..., -0.8025,  0.8391, -0.2643],\n",
              "          ...,\n",
              "          [ 0.2847,  0.0910,  0.2655,  ..., -0.1014,  0.0662,  0.1264],\n",
              "          [ 0.1165,  0.2137,  0.2766,  ..., -0.0876,  0.1311,  0.0450],\n",
              "          [-0.1805, -0.5028, -0.1872,  ...,  0.2993,  0.3353, -0.2752]],\n",
              " \n",
              "         [[ 0.3708, -0.1259, -0.1218,  ...,  0.4387,  0.6815,  0.8175],\n",
              "          [-0.0037,  0.1147, -0.1807,  ...,  0.4939,  0.7906, -0.2964],\n",
              "          [ 0.3419,  0.7693, -0.3490,  ...,  0.7129,  1.0267,  0.1576],\n",
              "          ...,\n",
              "          [ 0.4059,  0.3948,  0.1991,  ...,  0.1597,  0.3260,  1.2891],\n",
              "          [ 0.1780,  0.6412, -0.6818,  ..., -0.0096,  0.2766,  1.1257],\n",
              "          [ 0.0778, -0.0887, -0.2324,  ...,  0.3872,  0.3235,  0.3841]],\n",
              " \n",
              "         [[-0.1899,  0.3332, -0.2903,  ..., -0.3460,  0.4054,  0.5837],\n",
              "          [-0.3278,  0.3817, -0.9878,  ..., -0.3244,  0.7997,  0.1379],\n",
              "          [ 0.1466,  0.2848, -0.3038,  ..., -0.9809, -0.1487,  0.3755],\n",
              "          ...,\n",
              "          [-0.9050, -0.2865, -0.1235,  ...,  0.3544,  0.4196, -0.0365],\n",
              "          [-0.8016, -0.2559, -0.1856,  ...,  0.3950,  0.4338, -0.1697],\n",
              "          [-0.7346, -0.2838, -0.2178,  ...,  0.4359,  0.3919, -0.1729]]]),\n",
              " tensor([[-0.9018, -0.3883, -0.7451,  ..., -0.8394, -0.6117,  0.6867],\n",
              "         [-0.7585, -0.4638, -0.9114,  ..., -0.9656, -0.5245,  0.4084],\n",
              "         [-0.8920, -0.4542, -0.8641,  ..., -0.8886, -0.6859,  0.6971],\n",
              "         [-0.8888, -0.7805, -0.9993,  ..., -0.9924, -0.7944,  0.8092],\n",
              "         [-0.6271, -0.1364, -0.7894,  ..., -0.8675, -0.2967,  0.1622],\n",
              "         [-0.8770, -0.4566, -0.9789,  ..., -0.9786, -0.5337,  0.2696]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "869xwVelxs_z",
        "outputId": "edc180f5-d20a-4c05-f520-45901051d93a"
      },
      "source": [
        "model_output[0]"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.1730, -0.2285, -0.4436,  ..., -0.0600, -0.2608,  0.6115],\n",
              "         [ 0.4410,  0.4642, -0.6297,  ...,  0.3118,  0.7988,  0.6890],\n",
              "         [ 0.3267,  0.3485, -0.6775,  ..., -0.4906,  0.1210,  0.7811],\n",
              "         ...,\n",
              "         [ 0.3720,  0.1589, -0.0394,  ..., -0.5004, -0.4275,  0.0529],\n",
              "         [-0.4392, -0.2352, -0.3201,  ...,  0.1480,  0.0387, -0.2422],\n",
              "         [-0.3278, -0.3365, -0.3303,  ...,  0.0835, -0.1275, -0.0612]],\n",
              "\n",
              "        [[ 0.1139, -0.1046, -0.1401,  ..., -0.3234, -0.2775,  0.7110],\n",
              "         [ 0.1873,  0.3992, -0.1844,  ...,  0.4850,  0.8252,  0.4604],\n",
              "         [ 0.1450,  0.3667, -0.0930,  ..., -0.5656, -0.2463,  0.8268],\n",
              "         ...,\n",
              "         [-0.2153, -0.4368, -0.0599,  ...,  0.0941,  0.1570,  0.0618],\n",
              "         [-0.1771, -0.3815,  0.2083,  ..., -0.1897, -0.1277,  0.2641],\n",
              "         [-0.1634, -0.3891,  0.1858,  ..., -0.1735, -0.1737,  0.2126]],\n",
              "\n",
              "        [[ 0.1438, -0.3382, -0.4895,  ..., -0.1735, -0.2984,  0.7280],\n",
              "         [ 0.0452, -0.0023, -0.2324,  ...,  0.2091,  0.7673,  0.2560],\n",
              "         [-0.1807,  0.6633, -1.1347,  ..., -0.2864,  0.0127,  0.3594],\n",
              "         ...,\n",
              "         [ 0.1304,  0.0088,  0.1290,  ..., -0.6891, -0.5465, -0.0089],\n",
              "         [-0.3971, -0.7371, -0.4065,  ...,  0.2310,  0.3169, -0.0083],\n",
              "         [-0.0381, -0.2149,  0.1986,  ..., -0.1552, -0.1790,  0.2563]],\n",
              "\n",
              "        [[ 0.1039,  0.3671, -0.3329,  ..., -0.8287,  0.7350,  0.4272],\n",
              "         [ 0.3363,  0.2657, -0.2076,  ..., -0.6105,  0.5881,  0.2635],\n",
              "         [ 0.5736,  0.7119, -0.7245,  ..., -0.8025,  0.8391, -0.2643],\n",
              "         ...,\n",
              "         [ 0.2847,  0.0910,  0.2655,  ..., -0.1014,  0.0662,  0.1264],\n",
              "         [ 0.1165,  0.2137,  0.2766,  ..., -0.0876,  0.1311,  0.0450],\n",
              "         [-0.1805, -0.5028, -0.1872,  ...,  0.2993,  0.3353, -0.2752]],\n",
              "\n",
              "        [[ 0.3708, -0.1259, -0.1218,  ...,  0.4387,  0.6815,  0.8175],\n",
              "         [-0.0037,  0.1147, -0.1807,  ...,  0.4939,  0.7906, -0.2964],\n",
              "         [ 0.3419,  0.7693, -0.3490,  ...,  0.7129,  1.0267,  0.1576],\n",
              "         ...,\n",
              "         [ 0.4059,  0.3948,  0.1991,  ...,  0.1597,  0.3260,  1.2891],\n",
              "         [ 0.1780,  0.6412, -0.6818,  ..., -0.0096,  0.2766,  1.1257],\n",
              "         [ 0.0778, -0.0887, -0.2324,  ...,  0.3872,  0.3235,  0.3841]],\n",
              "\n",
              "        [[-0.1899,  0.3332, -0.2903,  ..., -0.3460,  0.4054,  0.5837],\n",
              "         [-0.3278,  0.3817, -0.9878,  ..., -0.3244,  0.7997,  0.1379],\n",
              "         [ 0.1466,  0.2848, -0.3038,  ..., -0.9809, -0.1487,  0.3755],\n",
              "         ...,\n",
              "         [-0.9050, -0.2865, -0.1235,  ...,  0.3544,  0.4196, -0.0365],\n",
              "         [-0.8016, -0.2559, -0.1856,  ...,  0.3950,  0.4338, -0.1697],\n",
              "         [-0.7346, -0.2838, -0.2178,  ...,  0.4359,  0.3919, -0.1729]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPGqbLCNxTEn",
        "outputId": "59423d47-f07d-465c-d656-22a0fa1674c6"
      },
      "source": [
        "model_output[1]"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.9018, -0.3883, -0.7451,  ..., -0.8394, -0.6117,  0.6867],\n",
              "        [-0.7585, -0.4638, -0.9114,  ..., -0.9656, -0.5245,  0.4084],\n",
              "        [-0.8920, -0.4542, -0.8641,  ..., -0.8886, -0.6859,  0.6971],\n",
              "        [-0.8888, -0.7805, -0.9993,  ..., -0.9924, -0.7944,  0.8092],\n",
              "        [-0.6271, -0.1364, -0.7894,  ..., -0.8675, -0.2967,  0.1622],\n",
              "        [-0.8770, -0.4566, -0.9789,  ..., -0.9786, -0.5337,  0.2696]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzh5gZ-axfgp",
        "outputId": "a4c49f4e-451c-4d17-b9df-893dd1a7eab3"
      },
      "source": [
        "#Perform pooling. In this case, max pooling\n",
        "sentence_embeddings_bert = max_pooling(model_output, encoded_input['attention_mask'])\n",
        "\n",
        "print(\"Sentence embeddings: Bert\")\n",
        "print(sentence_embeddings_bert)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence embeddings: Bert\n",
            "tensor([[ 0.8721,  1.0943,  1.4140,  ...,  0.3142,  0.7988,  1.4586],\n",
            "        [ 1.0921,  1.6610,  1.2811,  ...,  0.4850,  0.8252,  1.3723],\n",
            "        [ 0.9241,  1.4654,  1.1465,  ...,  0.2740,  0.7673,  1.4029],\n",
            "        [ 1.1887,  1.1802,  0.4218,  ..., -0.1099,  0.9717,  0.4272],\n",
            "        [ 0.9490,  1.1527,  1.5347,  ...,  0.7770,  1.3213,  1.5900],\n",
            "        [ 1.4372,  1.3312,  1.1156,  ...,  0.4308,  0.9271,  1.5311]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Uwt1_AbxTIB",
        "outputId": "d5148b29-d020-4334-bd3c-6b6841302506"
      },
      "source": [
        "print(\"Sentence embeddings: SBert\")\n",
        "print(sentence_embeddings_sbert)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence embeddings: SBert\n",
            "tensor([[ 5.4378e-02,  9.6291e-01,  1.9213e+00,  ...,  1.6476e-01,\n",
            "         -5.0602e-01,  5.4386e-01],\n",
            "        [ 2.4989e-01,  1.3479e+00,  1.3915e+00,  ...,  2.0159e-01,\n",
            "         -2.6415e-01,  8.0529e-01],\n",
            "        [ 3.3215e-01,  1.5401e+00,  2.8933e-01,  ..., -1.6547e-01,\n",
            "          8.3750e-03,  4.5810e-01],\n",
            "        [ 1.8371e-01,  9.1992e-01, -4.8081e-01,  ...,  4.1432e-01,\n",
            "         -9.3064e-04,  2.4924e-01],\n",
            "        [ 6.5023e-01,  1.1848e+00,  1.3291e+00,  ...,  6.5337e-01,\n",
            "          1.5838e+00,  1.3274e+00],\n",
            "        [ 7.8597e-01,  4.7389e-01,  4.5608e-01,  ..., -9.9444e-02,\n",
            "          9.9268e-01,  1.3300e+00]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_dkUfogxTK9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e1Ia55725V8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkXOhwVP25td"
      },
      "source": [
        "### Similarity score SBert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0P71FwM_29sG",
        "outputId": "d38b30cb-d481-41e4-f958-c944c76b7acd"
      },
      "source": [
        "#cosine similarity - SBert\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "print(cosine_similarity(sentence_embeddings_sbert, sentence_embeddings_sbert))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.         0.89349794 0.7808059  0.728122   0.7061805  0.6594599 ]\n",
            " [0.89349794 1.         0.76358527 0.7168366  0.79300374 0.72225964]\n",
            " [0.7808059  0.76358527 1.0000001  0.6484803  0.7265867  0.6744678 ]\n",
            " [0.728122   0.7168366  0.6484803  1.0000001  0.6005163  0.52225864]\n",
            " [0.7061805  0.79300374 0.7265867  0.6005163  0.9999999  0.8709479 ]\n",
            " [0.6594599  0.72225964 0.6744678  0.52225864 0.8709479  1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkyPBGtC3OFI"
      },
      "source": [
        "### Similarity score Bert + Max Pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6FLnljD29xl",
        "outputId": "856c5bc5-42b2-4911-fc28-902aae40f903"
      },
      "source": [
        "#cosine similarity - Bert + Max pooling\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "print(cosine_similarity(sentence_embeddings_bert, sentence_embeddings_bert))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.9999997  0.9563465  0.9465624  0.89467204 0.93351865 0.9284128 ]\n",
            " [0.9563465  1.0000002  0.93994844 0.90052104 0.94531024 0.93707633]\n",
            " [0.9465624  0.93994844 0.99999964 0.8899784  0.93335116 0.92260206]\n",
            " [0.89467204 0.90052104 0.8899784  1.         0.8841766  0.872373  ]\n",
            " [0.93351865 0.94531024 0.93335116 0.8841766  1.0000001  0.9502973 ]\n",
            " [0.9284128  0.93707633 0.92260206 0.872373   0.9502973  0.9999999 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MK5MY3G7sUNJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpFwZrG0ut53"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pbV3C7nut9r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}